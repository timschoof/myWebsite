[{"authors":["admin"],"categories":null,"content":"I am a Research Associate at the department of Speech, Hearing and Phonetic Sciences at UCL. My research primarily focuses on the question why older adults, with and without hearing loss, experience increased difficulties understanding speech in noise. I am particularly interested in the potential effects of cochlear synaptopathy, or \u0026lsquo;hidden hearing loss\u0026rsquo;, on speech perception. I have also looked at individual differences in hearing aid outcomes using different signal processing strategies. My aim is to ultimately be able to improve the listening experience of older adults. In addition to science, I absolutely love statistics and programming. When I am not working, I am either travelling the world, or planning a trip.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"/www.timschoof.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/www.timschoof.com/authors/admin/","section":"author","summary":"I am a Research Associate at the department of Speech, Hearing and Phonetic Sciences at UCL. My research primarily focuses on the question why older adults, with and without hearing loss, experience increased difficulties understanding speech in noise. I am particularly interested in the potential effects of cochlear synaptopathy, or \u0026lsquo;hidden hearing loss\u0026rsquo;, on speech perception. I have also looked at individual differences in hearing aid outcomes using different signal processing strategies.","tags":null,"title":"Tim Schoof","type":"author"},{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536447600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536447600,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"/www.timschoof.com/tutorial/","publishdate":"2018-09-09T00:00:00+01:00","relpermalink":"/www.timschoof.com/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.\n  Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using url_slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906545600,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/www.timschoof.com/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/www.timschoof.com/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":[],"content":"\rTL;DR You can download the code on github.\nFirst things first, let’s make sure you have all the require R packages installed and loaded.\nif (!require(here)) install.packages(\u0026quot;here\u0026quot;)\rif (!require(tidyverse)) install.packages(\u0026quot;tidyverse\u0026quot;)\rLet’s start by reading in our data file. We’ll assume that the data file will be in the following format: one row for each participant, whith each column indicating the ear and test frequency.\ndata\u0026lt;-read.csv(here(paste(csvFile,\u0026quot;.csv\u0026quot;,sep=\u0026quot;\u0026quot;)),header=T)\rTo learn more about pipes, check out this tutorial (Ctrl+Shit+M is the shortcut).\n","date":1553990400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553990400,"objectID":"c8ecfc8752bd76018b6c5075ff26b993","permalink":"/www.timschoof.com/post/plotting-audiograms-in-r/","publishdate":"2019-03-31T00:00:00Z","relpermalink":"/www.timschoof.com/post/plotting-audiograms-in-r/","section":"post","summary":"TL;DR You can download the code on github.\nFirst things first, let’s make sure you have all the require R packages installed and loaded.\nif (!require(here)) install.packages(\u0026quot;here\u0026quot;)\rif (!require(tidyverse)) install.packages(\u0026quot;tidyverse\u0026quot;)\rLet’s start by reading in our data file. We’ll assume that the data file will be in the following format: one row for each participant, whith each column indicating the ear and test frequency.\ndata\u0026lt;-read.csv(here(paste(csvFile,\u0026quot;.csv\u0026quot;,sep=\u0026quot;\u0026quot;)),header=T)\rTo learn more about pipes, check out this tutorial (Ctrl+Shit+M is the shortcut).","tags":[],"title":"Plotting audiograms in R","type":"post"},{"authors":["Axelle Calcus","**Tim Schoof**","Stuart Rosen","Barbara Shinn-Cunningham","Pamela Souza"],"categories":null,"content":"","date":1548979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548979200,"objectID":"1ed5b2a1e2fcd33ec5bd1f895c7a2f9c","permalink":"/www.timschoof.com/publication/earhear2019b/","publishdate":"2019-02-01T00:00:00Z","relpermalink":"/www.timschoof.com/publication/earhear2019b/","section":"publication","summary":"Objectives: This study aimed to evaluate the informational component of speech-on-speech masking. Speech perception in the presence of a competing talker involves not only informational masking, but a number of masking processes involving interaction of masker and target energy in the auditory periphery. Such peripherally generated masking can be eliminated by presenting the target and masker in opposite ears (dichotically). However, this also reduces informational masking by providing listeners with lateralization cues that support spatial release from masking. In tonal sequences, informational masking can be isolated by rapidly switching the lateralization of dichotic target and masker streams across the ears, presumably producing ambiguous spatial percepts that interfere with spatial release from masking. However, it is not clear if this technique works with speech materials. Design: Speech reception thresholds (SRTs) were measured in 17 young normal-hearing adults for sentences produced by a female talker in the presence of a competing male talker under three different conditions: diotic (target and masker in both ears), dichotic, and dichotic but switching the target and masker streams across the ears. Because switching rate and signal coherence were expected to influence the amount of IM observed, these two factors varied across conditions. When switches occurred, they were either at word boundaries or periodically (every 116 ms) and either with or without a brief gap (84 ms) at every switch point. In addition, SRTs were measured in a quiet condition to rule out audibility as a limiting factor. Results: SRTs were poorer for the four switching dichotic conditions than for the non-switching dichotic condition, but better than for the diotic condition. Periodic switches without gaps resulted in the worst SRTs compared to the other switch conditions, thus maximizing informational masking. Conclusions: These findings suggest that periodically switching the target and masker streams across the ears (without gaps) was the most efficient in disrupting spatial release from masking. Thus, this approach can be used in experiments that seek a relatively pure measure of informational masking, and could be readily extended to translational research.","tags":null,"title":"Switching streams across ears to evaluate informational masking of speech-on-speech","type":"publication"},{"authors":["Pamela Souza","Kathryn Arehart","**Tim Schoof**","Melinda Anderson","Dorina Strori","Lauren Balmert"],"categories":null,"content":"","date":1548979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548979200,"objectID":"4587ffbf88962214a7084f5e41e459c4","permalink":"/www.timschoof.com/publication/earhear2019a/","publishdate":"2019-02-01T00:00:00Z","relpermalink":"/www.timschoof.com/publication/earhear2019a/","section":"publication","summary":"Objectives. Previous work has suggested that individual characteristics, including amount of hearing loss, age, and working memory ability, may affect response to hearing aid signal processing.  The present study aims to extend work using metrics to quantify cumulative signal modifications under simulated conditions to real hearing aids worn in everyday listening environments.  Specifically, the goal was to determine whether individual factors such as working memory, age, and degree of hearing loss play a role in explaining how listeners respond to signal modifications caused by signal processing in real hearing aids, worn in the listener's everyday environment, over a period of time. Design. Participants were older adults (age range 54-90 years) with symmetrical mild-to-moderate sensorineural hearing loss.  We contrasted two distinct hearing aid fittings: one designated as mild signal processing and one as strong signal processing.  Forty-nine older adults were enrolled in the study and thirty-five participants had valid outcome data for both hearing aid fittings. The difference between the two settings related to the wide dynamic range compression (WDRC) and frequency compression features. Order of fittings was randomly assigned for each participant.  Each fitting was worn in the listener's everyday environments for approximately five weeks prior to outcome measurements. The trial was double blind, with neither the participant nor the tester aware of the specific fitting at the time of the outcome testing. Baseline measures included a full audiometric evaluation as well as working memory and spectral and temporal resolution.  The outcome was aided speech recognition in noise. Results. The two hearing aid fittings resulted in different amounts of signal modification, with significantly less modification for the mild signal processing fitting.  The effect of signal processing on speech intelligibility depended on an individual's age, working memory capacity, and degree of hearing loss. Adults who were older demonstrated progressively poorer speech recognition at high levels of signal modification.  Working memory interacted with signal processing, with individuals with lower working memory demonstrating low speech intelligibility in noise with both processing conditions, and individuals with higher working memory demonstrating better speech intelligibility in noise with the mild signal processing fitting.  Amount of hearing loss interacted with signal processing, but the effects were very small.  Individual spectral and temporal resolution did not contribute significantly to the variance in the speech intelligibility score. Conclusions. When the consequences of a specific set of hearing aid signal processing characteristics were quantified in terms of overall signal modification, there was a relationship between participant characteristics and recognition of speech at different levels of signal modification.  Because the hearing aid fittings used were constrained to specific fitting parameters that represent the extremes of the signal modification that might occur in clinical fittings, future work should focus on similar relationships with a wider range of signal processing parameters.","tags":null,"title":"Understanding variability in individual response to hearing aid signal processing in wearable hearing aids","type":"publication"},{"authors":["Guangting Mai","**Tim Schoof**","Peter Howell"],"categories":null,"content":"","date":1548633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548633600,"objectID":"ac67f0b2b3c1e5d14268ae0e13c425dc","permalink":"/www.timschoof.com/publication/neuroimage2019/","publishdate":"2019-01-28T00:00:00Z","relpermalink":"/www.timschoof.com/publication/neuroimage2019/","section":"publication","summary":"Phase-locked responses are vital for auditory perception and they may vary with participants' arousal state and age. Two phase-locked neural responses that reflect fine-grained acoustic properties of speech were examined in the current study: the frequency-following response (FFR) to the speech fundamental frequency (F0), which originates primarily from the auditory brainstem, and the theta-band phase-locked response (θ-PLV) to the speech envelope that originates from the auditory cortices. The ways these responses were affected by arousal in adults across a wide age-range (19–75 years) were examined. Extracts from electroencephalographic (EEG) responses to repeated syllables were classified into either high or low arousal state based on the occurrence of sleep spindles. The magnitudes of both FFRs and θ-PLVs were statistically greater in the high, than in the low, arousal state. The difference in θ-PLV between the two arousal states was significantly associated with sleep spindle density in the young, but not the older, adults. The results show that (1) arousal affects phase-locked processing of speech at cortical/sub-cortical sensory levels; and that (2) there is an interplay between aging and arousal state which indicates that sleep spindles have an age-dependent neuro-regulatory role on cortical processes. The results lay the grounds for studying how cognitive states affect early-stage neural activity in the auditory system across the lifespan.","tags":null,"title":"Modulation of phase-locked neural responses to speech during different arousal states is age-dependent","type":"publication"},{"authors":["Melinda Anderson","Varsha Rallapalli","**Tim Schoof**","Pamela Souza","Kathryn Arehart"],"categories":null,"content":"","date":1541116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541116800,"objectID":"2fefc214c9967d4f4cffcb9beacd62f2","permalink":"/www.timschoof.com/publication/ija2018/","publishdate":"2018-11-02T00:00:00Z","relpermalink":"/www.timschoof.com/publication/ija2018/","section":"publication","summary":"Clinicians have long used self-report methods to assess hearing aid benefit. However, there are fewer data as to whether self-report instruments can be used to compare differences between signal processing settings. This study examined how self-perceived performance varied as a function of modifications in signal processing using two self-report measures. Data were collected as part of a double-blind randomised crossover clinical trial. Participants were fit with two fittings: mild processing (slow time constants, disabled frequency lowering) and strong processing (fast time constants, frequency lowering enabled). The speech, spatial, and qualities of hearing (SSQ) questionnaire and the Effectiveness of Auditory Rehabilitation (EAR) questionnaire were collected at multiple time points. Older adults with sensorineural hearing loss who had not used hearing aids within the previous year participated (49 older adults were consented; 40 were included in the final data analyses). Findings show that listeners report a difference in perceived performance when hearing aid features are modified. Both self-report measures were able to capture this change in perceived performance. Self-report measures provide a tool for capturing changes in perceived performance when hearing aid processing features are modified and may enhance provision of an evidence-based hearing aid fitting.","tags":null,"title":"The use of self-report measures to examine changes in perception in response to fittings using different signal processing parameters","type":"publication"},{"authors":["**Tim Schoof**","Pamela Souza"],"categories":null,"content":"","date":1538348400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538348400,"objectID":"3c486762812ce4a803b4e93822641fb2","permalink":"/www.timschoof.com/publication/psyarxiv2018/","publishdate":"2018-10-01T00:00:00+01:00","relpermalink":"/www.timschoof.com/publication/psyarxiv2018/","section":"publication","summary":"Objective: Older hearing-impaired adults typically experience difficulties understanding speech in noise. Most hearing aids address this issue using digital noise reduction. While noise reduction does not necessarily improve speech recognition, it may reduce the resources required to process the speech signal. Those available resources may, in turn, aid the ability to perform another task while listening to speech (ie, multitasking). This study examined to what extent changing the strength of digital noise reduction in hearing aids affects the ability to multitask. Design: Multitasking was measured using a dual-task paradigm, combining a speech recognition task and a visual monitoring task. The speech recognition task involved sentence recognition in the presence of six-talker babble at signal-to-noise ratios (SNRs) of 2 and 7 dB. Participants were fit with commercially-available hearing aids programmed under three noise reduction settings: off, mild, strong. Study sample: 18 hearing-impaired older adults. Results: There were no effects of noise reduction on the ability to multitask, or on the ability to recognize speech in noise. Conclusions: Adjustment of noise reduction settings in the clinic may not invariably improve performance for some tasks.","tags":null,"title":"Multitasking with typical use of hearing aid noise reduction in older listeners","type":"publication"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536447600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536447600,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"/www.timschoof.com/tutorial/example/","publishdate":"2018-09-09T00:00:00+01:00","relpermalink":"/www.timschoof.com/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":["Pamela Souza","**Tim Schoof**","Jing Shen"],"categories":null,"content":"","date":1488326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488326400,"objectID":"ab28320f87c433a2a3a04861cf42a036","permalink":"/www.timschoof.com/publication/audiologytoday2017/","publishdate":"2017-03-01T00:00:00Z","relpermalink":"/www.timschoof.com/publication/audiologytoday2017/","section":"publication","summary":"Older adults are living longer and more active lives than ever before. For audiologists, that means a larger number of clients who present with both auditory and cognitive changes. As researchers study the role of cognition in listening, what do clinicians need to know to guide treatment decisions?","tags":null,"title":"Can individual cognitive abilities direct audiology treatment?","type":"publication"},{"authors":null,"categories":[],"content":"\rThis work was presented as a poster at the American Auditory Society’s Annual Scientific and Technology Conference, 2-4 March 2017, Scottsdale, AZ. You can download a copy of the poster here.\nThe National Institutes of Health have recently undertaken steps to enhance rigor and reproducibility of biomedical research. For example, grant applications are now required to explicitly address how the proposed research will achieve robust and unbiased results. Reproducibility is an integral part of science as it allows for research findings to be either validated or refuted and lets scientists successfully build upon previous research. Only when multiple studies, conducted by different scientists, demonstrate similar results can we obtain a reasonable approximation of how the world works. In this blog post I will review some useful tools and discuss some good practices that support transparency and reproducibility.\nTo ensure the reproducibility of your research, you just need to follow these five simple rules:\nPre-register your study\rDocument everything you do\rDon’t do anything by hand, script everything\rUse a version control system\rProvide open access to all publications, scripts, and data\r\rFollowing these five rules will not only help other researchers validate or refute your findings, it will also make your research less error-prone, enhance your efficiency and productivity, and make your collaborations more effective. Moreover, it sends a clear signal of transparency and trustworthiness.\nSo how should we go about following these rules? In the sections below I will discuss some good practices and provide some useful tools that will help enhance the transparency and reproducibility of your research. I will also point you to some useful training resources.\nPre-register your study\rA few years ago, a group of scientists wrote an open letter to the Guardian newspaper advocating for study pre-registration in scientific publishing. The idea is that your study design and analysis details are peer reviewed before you start data collection. This helps distinguish exploratory from confirmatory analyses, guards against p-hacking or cherry-picking of data and analyses, and overcomes publication bias.\nFor a list of journals that currently offer pre-registration, have a look here. Most hearing science journals do not yet offer pre-registration. Let’s convince them!\nEven if your journal of choice does not give you the option to submit your study design and analysis plan for peer review, you can still create a registered report via:\n\rCenter for Open Science\rAsPredicted\rClinicalTrials.gov\r\r\rDocument, document, document\rIt is incredibly important to carefully document every step of the research process. Keep track of precisely why, when, and how you conducted your research. Instead of using a paper notebook or a collection of word documents, use an electronic lab notebook. This allows you to store all your research output in one place, access your notebook wherever you are, search entries, and share your notes with your collaborators.\nThere are a bunch of different electronic lab notebooks out there. Some are free, others are quite costly. Some allow you to store large volumes of data, others are more basic. Find one that best suits your needs. Some electronic lab notebooks that may be worth exploring (in no particular order) are:\n\rOpen Science Framework\rSlack\rSciNote\rMicrosoft OneNote\rEvernote\rLabii\rLabArchives\reLabJournal\rLabGuru\r\rIt is also incredibly important to provide detailed documentation for your scripts and your data. If either you or someone else ever wants to re-use it, they’ll need all the help they can get to make sense of your scripts and data files.\n\rAvoid manual data processing\rIn order for research to be fully reproducible, you have to script absolutely everything. If you manipulate your data by hand at any point, it is difficult to replicate exactly what you did at a later stage. And it may be practically impossible for anyone else to reproduce your results.\nUse R (instead of SPSS) for your statistical analyses. You can download both R and RStudio - a graphical user interface for R - for free. Software Carpentry offers a short course that walks you through the basics of Bash. Interested in learning Python? There are a lot of courses and books out there, such as Learn Python the hard way or MIT’s Introduction to computer science and programming using Python.\nIn general, some great websites that provide online programming courses are:\n\rCoursera\rSoftware Carpentry\redX\rLynda (check if your university has a subscription)\r\rFeeling tired just thinking about the idea of having to spend hours working your way through an online course? The best way to learn is just to get your hands dirty. So for your next data analysis, just open up RStudio, or the Bash Shell and figure things out as you go along. As always, Google is your friend, as is stackoverflow.\n\rAutomatically embed stats in your manuscripts\rThe next step in making your research reproducible, is to integrate your data, code, and manuscript. That way you can trace back the results you report in your paper to the underlying code and data. Automatically embedding your statistical output in your manuscripts will avoid the risk of any copy-paste errors when reporting your results. Another advantage is that you can automatically update your graphs and statistics after you have re-analysed your data.\nThere are some nifty solutions out there to automatically embed statistical output in your manuscripts. For example, if you are a Microsoft Word user, you can download StatTag, a free plug-in that allows you to embed statistics, tables, and figures into Word and update your results with one button press. Alternatively, you can write dynamic documents directly from RStudio, using R Markdown (which in turn uses the knitr and pandoc R packages). Have a look at some of the things that are possible with R Markdown here.\nGetting started with R Markdown is fairly straightforward. Here are some useful resources to help you get started:\n\rswcarpentry.github.io/r-novice-gapminder/15-knitr-markdown\rwww.coursera.org/learn/reproducible-research\rR Markdown cheat sheet\r\rFormatting is of course very important when preparing manuscripts for publication. Instead of using Microsoft Word, you could use LaTeX and integrate your statistical output using Sweave and knitr. However, even if you’re not a LaTeX user, you can prepare nicely formatted manuscripts in RStudio. For information, have a look at this tutorial and consider using the rticles R package.\nIn addition to generating reports and manuscripts, it is possible to create interactive web applications in RStudio using shiny. You can show your data on the web and allow people to play with a set of parameters to see what effect they have on your results. For some fancy examples, have a look at this showcase.\n\rUse a version control system\rHave you ever had multiple versions of a certain file floating around on your computer, having forgotten which version was the ‘right’ one? This can be particularly problematic if months or years down the line someone asks if you’d be happy to share the code you used in your paper. The solution to this issue is to use a version control system, such as Git. You can use it to keep track of changes in your documents and scripts by storing revisions of your files in a centralized repository. Using a version control system you can easily compare, restore, and merge different versions of files. What is particularly nice is that you can undo changes you made to a given script and its dependent files simultaneously. Rather than having to try to remember which files were changed in conjunction with one another, you can undo the changes to these files all at once.\nTo start using Git as your version control system, you need to do two things:\n\rInstall Git on your computer\rCreate an account with GitHub or GitLab\r\rGit itself serves as the local version control system on your computer. GitHub and GitLab provide centralized repositories where you can manage and share your files with your collaborators or the world.\nRepositories on GitHub are in principle public, which means that anyone can look at and download your code (people can’t make changes to your code unless they have your permission). If you are not ready to share your work, you can make your repository private. Usually you have to pay to host private repositories on GitHub. However, if you have a university email address, you can request an educational discount and have as many private repositories as you want, for free. Instead of using GitHub, you can also create an account with GitLab. You can have an unlimited number of private repositories on their site.\nThere is a bit of a learning curve to getting started with Git, but it is well worth it! Here are some useful resources to get you on your way:\n\rSoftware Carpentry intro to Git\rGit documentation\rGitHub user guides\r\r\rPublish open access\rThere has been a recent push for open access publishing. An increasing number of funding agencies, such as the NIH, the Research Councils UK, and the Wellcome Trust have established policies for open access publishing.\nThere are many advantages to making your publications publicly available. It drives innovation on a global scale, gives clinicians access to the latest research findings, and gives you increased visibility and citations. For an excellent overview of why open access publishing is so important, have a look at this video rom “Piled Higher and Deeper”, by Jorge Cham (phdcomics.com).\nThere are a few different options to provide open access to your publications.\nPay an article processing charge\rDeposit paper in an open access repository after an embargo period\rSubmit the post-print version of the paper to an online repository\rPost PDFs of your publications on your personal website\r\r\rProvide open access to your scripts\rAnd important part of enhancing the transparency and reproducibility of your research is to share your code, along with some (example) data and documentation. This enables others to exactly replicate your analyses. Your code can then also be used in future research. It may even lead to some citations!\nYou can of course share your code and supporting documents as a bunch of individual files. However, a nice way to distribute your code is to create an R package to go along with your publication. Everything will be nicely packaged up together. All people need to do is install your package and they can play with your code and data in R. You can create an R package in RStudio using the devtools package. For some more information on how to go about it, have a look at this tutorial.\nIf you’re using a version control system, like GitHub, the easiest way to share your scripts or R package is to link to your GitHub repository in your publication. You can even make your repository citable by assigning it a doi. You can learn more about how to do that here.\nIt might even be worth writing a paper specifically about your analysis methods and code in journals, such as:\n\rJournal of Open Research Software\rThe Journal of Open Source Software\rThe R Journal\r\r\rProvide open access to your data\rLast but not least, in addition to making your publications and code open access, it is important to provide open access to your de-identified data. This enhances the transparency of your research, helps preserve your data for the future, and enables reuse (including meta-analysis) of your data. It is of course important to keep HIPAA compliance and any intellectual property rights in mind when deciding how to go about sharing your data.\nWhen you archive your data, it is important to include detailed documentation so that you and others can make sense of all the different parts of your data set. In a few months or years, it is quite likely that you won’t remember what all the different fields in your excel file refer to.\nDeposit your data and documentation in an online repository, such as:\n\rHarvard Data Verse\rfigshare\rDryad Digital Repository\rOpen Science Framework\rDat Project\rA repository hosted by your institution, funder, or journal\r\rAcknowledgments: Many thanks to Pamela Souza for making this work possible. Thanks to José Joaquín Atria and Sriram Boothalingam for inspiring discussions on the topic. Work supported by NIH. \n\r","date":1487721600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487721600,"objectID":"9b567939c5f61acbdc679e3dfc512b47","permalink":"/www.timschoof.com/post/enhancing-transparency-and-reproducibility-of-hearing-science/","publishdate":"2017-02-22T00:00:00Z","relpermalink":"/www.timschoof.com/post/enhancing-transparency-and-reproducibility-of-hearing-science/","section":"post","summary":"This work was presented as a poster at the American Auditory Society’s Annual Scientific and Technology Conference, 2-4 March 2017, Scottsdale, AZ. You can download a copy of the poster here.\nThe National Institutes of Health have recently undertaken steps to enhance rigor and reproducibility of biomedical research. For example, grant applications are now required to explicitly address how the proposed research will achieve robust and unbiased results. Reproducibility is an integral part of science as it allows for research findings to be either validated or refuted and lets scientists successfully build upon previous research.","tags":[],"title":"Enhancing transparency and reproducibility of hearing science","type":"post"},{"authors":null,"categories":null,"content":"My postdoctoral work at UCL looks at the potential implications of hidden hearing loss. Hidden hearing loss, or cochlear synaptopathy, refers to damage to the synapses connecting the inner hair cells in the cochlea to the auditory nerve. Crucially, this type of damage does not necessarily result in any changes in audiometric thresholds. Animal studies have shown that this damage can arise as a consequence of noise exposure or ageing. While evidence for hidden hearing loss in humans is emerging, it remains challenging to measure non-invasively. In addition, its consequences for auditory processing remain unclear. In particular, we are investigating the effects of hidden hearing loss on auditory temporal processing and speech perception in noise.\nI am also working on a project with Dr Sriram Boothalingam at the University of Wisconsin-Madison examining whether the auditory efferent system may play a protective role against hidden hearing loss.\n","date":1483225200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483225200,"objectID":"b0c24893c35395d5612504455d008492","permalink":"/www.timschoof.com/project/hhl/","publishdate":"2017-01-01T00:00:00+01:00","relpermalink":"/www.timschoof.com/project/hhl/","section":"project","summary":"Postdoc at UCL 2017-2019","tags":null,"title":"Consequences of hidden hearing loss","type":"project"},{"authors":["**Tim Schoof**","Stuart Rosen"],"categories":null,"content":"","date":1475276400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475276400,"objectID":"d917f8db24c0990b82d43a7215fddf3f","permalink":"/www.timschoof.com/publication/jaro2016/","publishdate":"2016-10-01T00:00:00+01:00","relpermalink":"/www.timschoof.com/publication/jaro2016/","section":"publication","summary":"Older adults, even those without hearing impairment, often experience increased difficulties understanding speech in the presence of background noise. This study examined the role of age-related declines in subcortical auditory processing in the perception of speech in different types of background noise. Participants included normal-hearing young (19–29 years) and older (60–72 years) adults. Normal hearing was defined as pure-tone thresholds of 25 dB HL or better at octave frequencies from 0.25 to 4 kHz in both ears and at 6 kHz in at least one ear. Speech reception thresholds (SRTs) to sentences were measured in steady-state (SS) and 10-Hz amplitude-modulated (AM) speech-shaped noise, as well as two-talker babble. In addition, click-evoked auditory brainstem responses (ABRs) and envelope following responses (EFRs) in response to the vowel /ɑ/ in quiet, SS, and AM noise were measured. Of primary interest was the relationship between the SRTs and EFRs. SRTs were significantly higher (i.e., worse) by about 1.5 dB for older adults in two-talker babble but not in AM and SS noise. In addition, the EFRs of the older adults were less robust compared to the younger participants in quiet, AM, and SS noise. Both young and older adults showed a “neural masking release,” indicated by a more robust EFR at the trough compared to the peak of the AM masker. The amount of neural masking release did not differ between the two age groups. Variability in SRTs was best accounted for by audiometric thresholds (pure-tone average across 0.5–4 kHz) and not by the EFR in quiet or noise. Aging is thus associated with a degradation of the EFR, both in quiet and noise. However, these declines in subcortical neural speech encoding are not necessarily associated with impaired perception of speech in noise, as measured by the SRT, in normal-hearing older adults.","tags":null,"title":"The role of age-related declines in subcortical auditory processing in speech perception in noise","type":"publication"},{"authors":["**Tim Schoof**","Stuart Rosen"],"categories":null,"content":"","date":1441062000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441062000,"objectID":"13af1eeac12212eaf6f0b76ba1a95513","permalink":"/www.timschoof.com/publication/jasa-el2015/","publishdate":"2015-09-01T00:00:00+01:00","relpermalink":"/www.timschoof.com/publication/jasa-el2015/","section":"publication","summary":"This study examined the effects of sentence predictability and masker modulation type on the fluctuating masker benefit (FMB), the improvement in speech reception thresholds resulting from fluctuations imposed on a steady-state masker. Square-wave modulations resulted in a larger FMB than sinusoidal ones. FMBs were also larger for high compared to low-predictability sentences, indicating that high sentence predictability increases the benefits from glimpses of the target speech in the dips of the fluctuating masker. In addition, sentence predictability appears to have a greater effect on sentence intelligibility when the masker is fluctuating than when it is steady-state.","tags":null,"title":"High sentence predictability increases the fluctuating masker benefit","type":"publication"},{"authors":null,"categories":null,"content":"My postdoctoral work at Northwestern University focused on understanding individual differences that predict hearing aid outcomes, including speech in noise perception, listening effort, and perceived sound quality. Previous laboratory-based studies suggest a link between an individual\u0026rsquo;s susceptibility to signal modification caused by hearing aid processing and cognitive function. I worked on a clinical trial, using commercially available hearing aids, that investigated the effects of signal modification introduced by wide-dynamic range compression speed and frequency compression. We found that hearing aid outcomes relate to individual differences in audiometric thresholds, age, and working memory capacity.\n","date":1430434800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430434800,"objectID":"ab2073e275dd86789ff3ead9ccb635db","permalink":"/www.timschoof.com/project/has/","publishdate":"2015-05-01T00:00:00+01:00","relpermalink":"/www.timschoof.com/project/has/","section":"project","summary":"Postdoc at Northwestern University 2015-2016","tags":null,"title":"Individual differences in hearing aid outcomes","type":"project"},{"authors":["**Tim Schoof**","Stuart Rosen"],"categories":null,"content":"","date":1415750400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1415750400,"objectID":"bc1d86a0bdeabe6c7acc06ab59af5c26","permalink":"/www.timschoof.com/publication/frontiers2014/","publishdate":"2014-11-12T00:00:00Z","relpermalink":"/www.timschoof.com/publication/frontiers2014/","section":"publication","summary":"Normal-hearing older adults often experience increased difficulties understanding speech in noise. In addition, they benefit less from amplitude fluctuations in the masker. These difficulties may be attributed to an age-related auditory temporal processing deficit. However, a decline in cognitive processing likely also plays an important role. This study examined the relative contribution of declines in both auditory and cognitive processing to the speech in noise performance in older adults. Participants included older (60–72 years) and younger (19–29 years) adults with normal hearing. Speech reception thresholds (SRTs) were measured for sentences in steady-state speech-shaped noise (SS), 10-Hz sinusoidally amplitude-modulated speech-shaped noise (AM), and two-talker babble. In addition, auditory temporal processing abilities were assessed by measuring thresholds for gap, amplitude-modulation, and frequency-modulation detection. Measures of processing speed, attention, working memory, Text Reception Threshold (a visual analog of the SRT), and reading ability were also obtained. Of primary interest was the extent to which the various measures correlate with listeners' abilities to perceive speech in noise. SRTs were significantly worse for older adults in the presence of two-talker babble but not SS and AM noise. In addition, older adults showed some cognitive processing declines (working memory and processing speed) although no declines in auditory temporal processing. However, working memory and processing speed did not correlate significantly with SRTs in babble. Despite declines in cognitive processing, normal-hearing older adults do not necessarily have problems understanding speech in noise as SRTs in SS and AM noise did not differ significantly between the two groups. Moreover, while older adults had higher SRTs in two-talker babble, this could not be explained by age-related cognitive declines in working memory or processing speed.","tags":null,"title":"The role of auditory and cognitive factors in understanding speech in noise by normal-hearing older listeners","type":"publication"},{"authors":["**Tim Schoof**","Tim Green","Andrew Faulkner","Stuart Rosen"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"077334f8cd40548afe99ce0f78a27ca4","permalink":"/www.timschoof.com/publication/jasa2013/","publishdate":"2013-01-01T00:00:00Z","relpermalink":"/www.timschoof.com/publication/jasa2013/","section":"publication","summary":"Acoustic simulations were used to study the contributions of spatial hearing that may arise from combining a cochlear implant with either a second implant or contralateral residual low-frequency acoustic hearing. Speech reception thresholds (SRTs) were measured in twenty-talker babble. Spatial separation of speech and noise was simulated using a spherical head model. While low-frequency acoustic information contralateral to the implant simulation produced substantially better SRTs there was no effect of spatial cues on SRT, even when interaural differences were artificially enhanced. Simulated bilateral implants showed a significant head shadow effect, but no binaural unmasking based on interaural time differences, and weak, inconsistent overall spatial release from masking. There was also a small but significant non-spatial summation effect. It appears that typical cochlear implant speech processing strategies may substantially reduce the utility of spatial cues, even in the absence of degraded neural processing arising from auditory deprivation.","tags":null,"title":"Advantages from bilateral hearing in speech perception in noise with simulated cochlear implants and residual acoustic hearing","type":"publication"},{"authors":null,"categories":null,"content":"My PhD research addressed the question why older adults with normal hearing experience increased difficulties understanding speech in the presence of background noise. I looked at the relative contributions of age-related declines in subcortical auditory processing, as measured by the auditory brainstem response (ABR) and the frequency following response (FFR), and declines in cognitive processing. In short, the data suggested that age-related declines in auditory and cognitive processing, in the absence of hearing impairment, do not necessarily lead to increased speech in noise difficulties.\n","date":1314831600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1314831600,"objectID":"c9a66b2d3f935438f991c02f81127b35","permalink":"/www.timschoof.com/project/phd/","publishdate":"2011-09-01T00:00:00+01:00","relpermalink":"/www.timschoof.com/project/phd/","section":"project","summary":"PhD at UCL 2011 - 2014","tags":null,"title":"Effects of ageing on speech perception in noise","type":"project"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/www.timschoof.com/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/www.timschoof.com/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]